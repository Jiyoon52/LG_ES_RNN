{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ELwacWvdc69u",
    "outputId": "7bd7b3b3-2b04-479b-def2-bd5d8f29baea"
   },
   "outputs": [],
   "source": [
    "!pip install IPython\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jAM51Z7znq_V"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/Jiyoon52/LG_ES_RNN.git # colab 사용시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dYCNeMYEnq_Q"
   },
   "outputs": [],
   "source": [
    "# Image('image/image1.JPG') # 로컬 사용시\n",
    "Image('/content/LG_ES_RNN/image/image1.JPG') # colab 사용시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image('/content/LG_ES_RNN/image/image2.JPG')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9uXbP9sNnq_S"
   },
   "source": [
    "# [Recurrent Neural Networks - 분류] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QL7l9L4Jnq_T"
   },
   "source": [
    "##### jupyter notebook 단축키\n",
    "\n",
    "- ctrl+enter: 셀 실행   \n",
    "- shift+enter: 셀 실행 및 다음 셀 이동   \n",
    "- alt+enter: 셀 실행, 다음 셀 이동, 새로운 셀 생성\n",
    "- a: 상단에 새로운 셀 만들기\n",
    "- b: 하단에 새로운 셀 만들기\n",
    "- dd: 셀 삭제(x: 셀 삭제)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fr9IowEpnq_U"
   },
   "source": [
    "### 1. 모듈 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9ueLs11Jnq_W"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import time\n",
    "import copy\n",
    "\n",
    "import random\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt     \n",
    "import itertools\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KL9O-z5Pnq_Y"
   },
   "source": [
    "### 2. 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cXyA4QPJc69z"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "https://hoya012.github.io/blog/reproducible_pytorch/\n",
    "'''\n",
    "random_seed = 2022\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed_all(random_seed) # if use multi-GPU\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://archive.ics.uci.edu/ml/datasets/human+activity+recognition+using+smartphones\n",
    "- 스마트폰을 허리에 착용하고 6가지 활동 (Walking, Walking Upstairs, Walking Downstairs, Sitting, Standing, Laying)을 수행할 때 측정된 센서 데이터\n",
    "- 누락된 데이터에 대해 정제된 데이터\n",
    "- X: 여러 실험자에 대하여 561개의 변수를 수집한 시계열 데이터\n",
    "- y: 실험자의 상태 클래스 (0(Walking) / 1(Walking Upstairs) / 2(Walking Downstairs) / 3(Sitting) / 4(Standing) / 5(Laying))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y4t-KvVLnq_Z"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('/content/LG_ES_RNN/data/cls_train.csv')\n",
    "test = pd.read_csv('/content/LG_ES_RNN/data/cls_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qEXesS9Dnq_Z"
   },
   "source": [
    "#### 2.1 Data Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BKSKQHdqnq_a",
    "outputId": "9ddfb1d9-bc50-415d-d095-672bb0a760d4"
   },
   "outputs": [],
   "source": [
    "train.head() # 상위 5개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e94ovbFlnq_a",
    "outputId": "ee3f6ec6-4442-452d-8049-916165c97ace"
   },
   "outputs": [],
   "source": [
    "train.tail() # 하위 5개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gqZPizHfnq_b",
    "outputId": "ebc5509a-10a7-430c-8616-8e915df2ba5f"
   },
   "outputs": [],
   "source": [
    "train.shape # 데이터 차원 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mkym7Av-nq_b",
    "outputId": "44755160-eca6-4804-ea36-3ec11a5903cb"
   },
   "outputs": [],
   "source": [
    "train.describe() # 데이터 통계값 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rSYIsG_5nq_b",
    "outputId": "77e02336-470d-4a78-b883-e2c88dc3aeb9"
   },
   "outputs": [],
   "source": [
    "train['Activity'].value_counts() # 데이터 클래스 정보 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M-E5F22fc691",
    "outputId": "5f4fdbb2-cc14-4e94-8bad-1ad47f72c834"
   },
   "outputs": [],
   "source": [
    "x_train = train.drop(['subject', 'Activity'], axis=1)\n",
    "x_test = test.drop(['subject', 'Activity'], axis=1)\n",
    "y_train = train['Activity']\n",
    "y_test = test['Activity']\n",
    "\n",
    "print(f'x_train shape is {x_train.shape}')\n",
    "print(f'y_train shape is {y_train.shape}')\n",
    "print('-'*35)\n",
    "print(f'x_test shape is {x_test.shape}')\n",
    "print(f'y_test shape is {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kn_PAttSc691"
   },
   "outputs": [],
   "source": [
    "label_encoder = preprocessing.LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(y_train)\n",
    "y_test = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lWFECi_pc692",
    "outputId": "2d803f0c-52f0-4e72-fe1c-275adbad4c83"
   },
   "outputs": [],
   "source": [
    "print(pd.Series(y_train).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AJWVuJiec692"
   },
   "source": [
    "#### 2.2 Data Windowing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image('/content/LG_ES_RNN/image/image3.JPG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image('/content/LG_ES_RNN/image/image4.JPG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B1lhQRM_c692"
   },
   "outputs": [],
   "source": [
    "def windowing_process(x, y, window_size, shift_size, last = True):\n",
    "    x = x.reset_index(drop=True)\n",
    "    \n",
    "    x_window = []\n",
    "    y_window = []\n",
    "    \n",
    "    for start_idx in range(0, x.shape[0] - window_size + 1, shift_size):\n",
    "        x_window.append(x[start_idx:start_idx + window_size])\n",
    "        \n",
    "        if last == True:\n",
    "            y_window.append(y[start_idx + window_size - 1]) # 마지막 index의 class를 사용하는 경우\n",
    "        \n",
    "        else:\n",
    "            count_class = Counter(y[start_idx:start_idx + window_size])\n",
    "            y_window.append(count_class.most_common(n=1)[0][0]) # 가장 많이 빈출한 class를 사용하는 경우\n",
    "        \n",
    "    x_window = np.array(x_window)\n",
    "    y_window = np.array(y_window)\n",
    "    \n",
    "    return x_window, y_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nwg83gIec693",
    "outputId": "bfa8debb-212f-4da5-a7e6-3e8544d7220e"
   },
   "outputs": [],
   "source": [
    "x_train, y_train = windowing_process(x_train, y_train, 10, 1, True)\n",
    "x_test, y_test = windowing_process(x_test, y_test, 10, 1, True)\n",
    "\n",
    "print(f'x_train shape is {x_train.shape}')\n",
    "print(f'y_train shape is {y_train.shape}')\n",
    "print('-'*35)\n",
    "print(f'x_test shape is {x_test.shape}')\n",
    "print(f'y_test shape is {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PXvKEfdLc693",
    "outputId": "83305dc2-7b5b-4e95-f2cd-a2dc26645951"
   },
   "outputs": [],
   "source": [
    "n_train = int(0.8 * len(x_train))\n",
    "x_valid, y_valid = x_train[n_train:], y_train[n_train:]\n",
    "x_train, y_train = x_train[:n_train], y_train[:n_train]\n",
    "\n",
    "print(f'x_train shape is {x_train.shape}') # (batch_size x seq_len x input_size)\n",
    "print(f'y_train shape is {y_train.shape}')\n",
    "print('-'*35)\n",
    "print(f'x_train shape is {x_valid.shape}')\n",
    "print(f'y_train shape is {y_valid.shape}')\n",
    "print('-'*35)\n",
    "print(f'x_test shape is {x_test.shape}')\n",
    "print(f'y_test shape is {y_test.shape}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zxG4ygKAnq_e"
   },
   "source": [
    "### 3. RNN Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ae70Swl6c694"
   },
   "source": [
    "#### 3.1 Define the Model Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image('/content/LG_ES_RNN/image/image5.JPG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jmJd0HwPnq_f"
   },
   "outputs": [],
   "source": [
    "# https://pytorch.org/docs/stable/generated/torch.nn.RNN.html\n",
    "\n",
    "class RNN_model(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes, bidirectional, device='cuda'):\n",
    "        super(RNN_model, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.num_classes = num_classes\n",
    "        self.num_directions = 2 if bidirectional == True else 1\n",
    "        self.device = device\n",
    "        \n",
    "        # recurrent layer 설정\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True, bidirectional=bidirectional)\n",
    "\n",
    "        # bidirectional에 따른 fc layer 구축\n",
    "        # bidirectional 여부에 따라 hidden state의 shape가 달라짐 (True: 2 * hidden_size, False: hidden_size)\n",
    "        self.fc = nn.Linear(self.num_directions * hidden_size, self.num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # data dimension: (batch_size x input_size x seq_len) -> (batch_size x seq_len x input_size)로 변환\n",
    "        # x = torch.transpose(x, 1, 2)\n",
    "        \n",
    "        # initial hidden states 설정\n",
    "        h0 = torch.zeros(self.num_directions * self.num_layers, x.size(0), self.hidden_size).to(self.device)\n",
    "        \n",
    "        # RNN으로부터 output 도출\n",
    "        out, _ = self.rnn(x, h0)  # out: tensor of shape (batch_size, seq_length, hidden_size)       \n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image('/content/LG_ES_RNN/image/image6.JPG')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q-Spp7zyc695"
   },
   "source": [
    "#### 3.2 Define The Training Testing Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ap0oUeuZc695"
   },
   "outputs": [],
   "source": [
    "class Train_Test():\n",
    "    def __init__(self,  train_loader, valid_loader, test_loader, input_size, num_classes, device='cuda'):\n",
    "        self.train_loader = train_loader\n",
    "        self.valid_loader = valid_loader\n",
    "        self.test_loader = test_loader\n",
    "        self.input_size = input_size\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def train(self, model, dataloaders, criterion, num_epochs, optimizer):\n",
    "        since = time.time() \n",
    "\n",
    "        train_loss_history = []        \n",
    "        val_loss_history = []\n",
    "\n",
    "        best_model_wts = copy.deepcopy(model.state_dict()) # 모델의 초기 Weight값 (각 Layer 별 초기 Weight값이 저장되어 있음)\n",
    "        best_acc = 0.0 # ACC는 클수록 좋은 metric이므로, 초기 낮은 값에서 갱신\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            if epoch == 0 or (epoch + 1) % 10 == 0:\n",
    "                print()\n",
    "                print('Epoch {}/{}'.format(epoch + 1, num_epochs))\n",
    "\n",
    "            # 각 epoch마다 순서대로 training과 validation을 진행\n",
    "            for phase in ['train', 'val']:\n",
    "                if phase == 'train':\n",
    "                    model.train()  # 모델을 training mode로 설정\n",
    "                else:\n",
    "                    model.eval()   # 모델을 validation mode로 설정\n",
    "\n",
    "                running_loss = 0.0\n",
    "                running_corrects = 0\n",
    "                running_total = 0\n",
    "\n",
    "                # training과 validation 단계에 맞는 dataloader에 대하여 학습/검증 진행\n",
    "                for inputs, labels in dataloaders[phase]:\n",
    "                    inputs = inputs.to(device)\n",
    "                    labels = labels.to(device, dtype=torch.long)\n",
    "                    # seq_lens = seq_lens.to(self.parameter['device'])\n",
    "                    \n",
    "                    # parameter gradients를 0으로 설정\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # forward\n",
    "                    # training 단계에서만 gradient 업데이트 수행\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "\n",
    "                        # input을 model에 넣어 output을 도출한 후, loss를 계산함\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                        # output 중 최댓값의 위치에 해당하는 class로 예측을 수행\n",
    "                        _, preds = torch.max(outputs, 1) # 첫 _에는 원래 실제 max값이 들어감 \n",
    "\n",
    "                        # backward (optimize): training 단계에서만 수행\n",
    "                        if phase == 'train':\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "\n",
    "                    # batch별 loss를 축적함\n",
    "                    running_loss += loss.item() * inputs.size(0)\n",
    "                    running_corrects += torch.sum(preds == labels.data)\n",
    "                    running_total += labels.size(0)\n",
    "\n",
    "                # epoch의 loss 및 accuracy 도출\n",
    "                epoch_loss = running_loss / running_total\n",
    "                epoch_acc = running_corrects.double() / running_total\n",
    "\n",
    "                if epoch == 0 or (epoch + 1) % 10 == 0:\n",
    "                    print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "                # validation 단계에서 validation loss가 감소할 때마다 best model 가중치를 업데이트함\n",
    "                if phase == 'val' and epoch_acc > best_acc:\n",
    "                    best_acc = epoch_acc\n",
    "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                if phase == 'train':\n",
    "                    train_loss_history.append(epoch_loss)\n",
    "                elif phase == 'val':\n",
    "                    val_loss_history.append(epoch_loss)\n",
    "\n",
    "\n",
    "        # 전체 학습 시간 계산 (학습이 완료된 후)\n",
    "        time_elapsed = time.time() - since\n",
    "        print('\\nTraining complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "        print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "        # validation loss가 가장 낮았을 때의 best model 가중치를 불러와 best model을 구축함\n",
    "        model.load_state_dict(best_model_wts)\n",
    "        return model, train_loss_history, val_loss_history\n",
    "\n",
    "    def test(self, model, test_loader):\n",
    "        model.eval()   # 모델을 validation mode로 설정\n",
    "        \n",
    "        # test_loader에 대하여 검증 진행 (gradient update 방지)\n",
    "        with torch.no_grad():\n",
    "            corrects = 0\n",
    "            total = 0\n",
    "            preds = []\n",
    "            probs = []\n",
    "            for inputs, labels in test_loader:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device, dtype=torch.long)\n",
    "\n",
    "                # forward\n",
    "                # input을 model에 넣어 output을 도출\n",
    "                outputs = model(inputs)\n",
    "                prob = outputs\n",
    "                prob = nn.Softmax(dim=1)(prob)\n",
    "                \n",
    "                # output 중 최댓값의 위치에 해당하는 class로 예측을 수행\n",
    "                _, pred = torch.max(outputs, 1)\n",
    "                \n",
    "                # batch별 정답 개수를 축적함\n",
    "                corrects += torch.sum(pred == labels.data)\n",
    "                total += labels.size(0)\n",
    "\n",
    "                preds.extend(pred.detach().cpu().numpy())\n",
    "                probs.extend(prob.detach().cpu().numpy())\n",
    "\n",
    "            preds = np.array(preds)\n",
    "            probs = np.array(probs)\n",
    "            acc = (corrects.double() / total).item()\n",
    "       \n",
    "        return preds, probs, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YQpDFx6Qc695"
   },
   "source": [
    "### 4. Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hbeoKHtuc695"
   },
   "source": [
    "#### 4.1 Hyperparameter Setting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- batch_size: 학습 및 검증에 사용할 배치의 크기\n",
    "- input_size: 변수 개수\n",
    "- num_classes: 데이터의 class 개수\n",
    "- hidden_size: 모델의 hidden dimension\n",
    "- num_layers: 모델의 layer 개수\n",
    "- bidirectional: 모델의 양방향성 여부\n",
    "- num_epochs: 학습할 epoch 횟수\n",
    "- device: 사용할 자원 선정\n",
    "- best_model_path: 모델 파라미터 저장 위치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3lfRBlHOc696"
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "input_size = x_train.shape[2]\n",
    "num_classes = len(np.unique(y_train))\n",
    "hidden_size = 64\n",
    "num_layers = 2\n",
    "bidirectional = True\n",
    "num_epochs = 200\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else 'cpu') \n",
    "best_model_path = '/content/LG_ES_RNN/ckpt/rnn_cls.pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "11pwiKxvc696"
   },
   "source": [
    "#### 4.2 Construct Data Loaders and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Esu5Edr4c696"
   },
   "outputs": [],
   "source": [
    "datasets = []\n",
    "for dataset in [(x_train, y_train), (x_valid, y_valid), (x_test, y_test)]:\n",
    "    x_data = dataset[0]\n",
    "    y_data = dataset[1]\n",
    "    datasets.append(torch.utils.data.TensorDataset(torch.Tensor(x_data), torch.Tensor(y_data)))\n",
    "\n",
    "trainset, validset, testset = datasets[0], datasets[1], datasets[2]\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(validset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iWVWVD-mc696"
   },
   "outputs": [],
   "source": [
    "model =  RNN_model(input_size, hidden_size, num_layers, num_classes, bidirectional, device)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C6KK9j8rc696"
   },
   "source": [
    "#### 4.3 Model Training and Save Weights(Parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8osspfZyc696"
   },
   "outputs": [],
   "source": [
    "dataloaders_dict = {'train': train_loader, 'val': valid_loader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "89HzclOfc697"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bJaQGNNTc697",
    "outputId": "527de81d-89dd-466a-8ba4-3ae8f46180aa"
   },
   "outputs": [],
   "source": [
    "trainer = Train_Test(train_loader, valid_loader, test_loader, input_size, num_classes, device)\n",
    "best_model, train_loss_history, val_loss_history = trainer.train(model, dataloaders_dict, criterion, num_epochs, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wSOL8zL6c697"
   },
   "outputs": [],
   "source": [
    "torch.save(best_model.state_dict(), best_model_path) # 파라미터 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v1BkcpZWc697"
   },
   "source": [
    "### 5. Model Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tZb-AakIc697"
   },
   "source": [
    "#### 5.1 Loss History Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O8OIfAq-c697",
    "outputId": "ba794f3e-87a5-4d1c-9245-caf2cb83459d"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "plt.title('Loss History')\n",
    "plt.plot(range(num_epochs), train_loss_history, c='blue', label='Train Loss')\n",
    "plt.plot(range(num_epochs), val_loss_history, c='red', label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BcaDN3J1c697"
   },
   "source": [
    "#### 5.2 Load Model Weights(Parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RW45Ia_5c697",
    "outputId": "d153d9a7-01fa-4a5b-e46a-c8ad34d801bd"
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(best_model_path)) # 저장된 파라미터 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fLj9eHRoc698",
    "outputId": "8bb621f8-8993-44e8-a293-1a1f322140bc"
   },
   "outputs": [],
   "source": [
    "y_pred, y_prob, acc = trainer.test(model, test_loader)\n",
    "print(y_pred[0])\n",
    "print(y_prob[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9GY8aEm3c698",
    "outputId": "ed13c7e5-e520-49a7-af82-cb62f86f0ba1"
   },
   "outputs": [],
   "source": [
    "pd.Series(y_prob[0]).plot(kind='bar')\n",
    "plt.title('Predicted probability per class')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Predicted probability')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image('/content/LG_ES_RNN/image/image7.JPG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aoP9XLsrc698",
    "outputId": "d745155e-1e15-4baa-abd1-4692f28fdc72"
   },
   "outputs": [],
   "source": [
    "cr = pd.DataFrame(classification_report(y_test, y_pred, target_names=list(label_encoder.classes_), output_dict=True))\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NXzTLOhmc698",
    "outputId": "3ebad1e0-885a-46ea-ced1-07a764a7f0ad"
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "def plot_confusion_matrix(con_mat, labels, title='Confusion Matrix', cmap=plt.cm.get_cmap('Blues'), normalize=False):\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.imshow(con_mat, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title, fontsize=11)\n",
    "    plt.colorbar(fraction=0.046, pad=0.04)\n",
    "    \n",
    "    marks = np.arange(len(labels))\n",
    "    nlabels = []\n",
    "    for k in range(len(con_mat)):\n",
    "        n = sum(con_mat[k])\n",
    "        nlabel = '{0} (n={1})'.format(labels[k],n)\n",
    "        nlabels.append(nlabel)\n",
    "    plt.xticks(marks, labels, fontsize=10)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.yticks(marks, nlabels, fontsize=10)\n",
    "\n",
    "    thresh = con_mat.max() / 2.\n",
    "    if normalize:\n",
    "        for i, j in itertools.product(range(con_mat.shape[0]), range(con_mat.shape[1])):\n",
    "            plt.text(j, i, '{0}%'.format(con_mat[i, j] * 100 / n), horizontalalignment=\"center\", color=\"white\" if con_mat[i, j] > thresh else \"black\")\n",
    "    else:\n",
    "        for i, j in itertools.product(range(con_mat.shape[0]), range(con_mat.shape[1])):\n",
    "            plt.text(j, i, con_mat[i, j], horizontalalignment=\"center\", color=\"white\" if con_mat[i, j] > thresh else \"black\")\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label\\n', fontsize=11)\n",
    "    plt.xlabel('\\nPredicted label', fontsize=11)\n",
    "    plt.show()\n",
    "    \n",
    "plot_confusion_matrix(cm, labels=list(label_encoder.classes_), normalize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gqBHwh5-nq_q"
   },
   "source": [
    "# EOD"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "1_RNN_classification.ipynb",
   "provenance": [
    {
     "file_id": "https://github.com/Jiyoon52/LG_ES_RNN/blob/main/1_RNN_classification.ipynb",
     "timestamp": 1656959181030
    },
    {
     "file_id": "https://github.com/Jiyoon52/LG_time_series_day02_dataset/blob/main/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%EC%8B%9C%EA%B3%84%EC%97%B4%EB%B6%84%EC%84%9D%202%ED%9A%8C%EC%B0%A8%20-%201.ipynb",
     "timestamp": 1642046886935
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc": {
   "base_numbering": "1",
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
