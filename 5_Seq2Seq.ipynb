{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"F2eg6OU7eZKP","outputId":"fc80ea17-f37e-47ad-9006-f6e75152495f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: IPython in c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages (7.31.1)\n","Requirement already satisfied: colorama in c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages (from IPython) (0.4.4)\n","Requirement already satisfied: backcall in c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages (from IPython) (0.2.0)\n","Requirement already satisfied: matplotlib-inline in c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages (from IPython) (0.1.3)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages (from IPython) (3.0.20)\n","Requirement already satisfied: setuptools>=18.5 in c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages (from IPython) (59.5.0)\n","Requirement already satisfied: pickleshare in c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages (from IPython) (0.7.5)\n","Requirement already satisfied: jedi>=0.16 in c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages (from IPython) (0.18.1)\n","Requirement already satisfied: decorator in c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages (from IPython) (5.1.1)\n","Requirement already satisfied: pygments in c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages (from IPython) (2.10.0)\n","Requirement already satisfied: traitlets>=4.2 in c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages (from IPython) (5.1.1)\n","Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages (from jedi>=0.16->IPython) (0.8.3)\n","Requirement already satisfied: wcwidth in c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->IPython) (0.2.5)\n"]},{"name":"stderr","output_type":"stream","text":["WARNING: Ignoring invalid distribution -orch (c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution - (c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -orch (c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution - (c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -orch (c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution - (c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -orch (c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution - (c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -orch (c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution - (c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -orch (c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution - (c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages)\n"]}],"source":["!pip install IPython\n","from IPython.display import Image"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jXS5MqJNeZKR","outputId":"facf067f-3106-44ec-d738-4d762624e9df"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting en-core-web-sm==3.1.0\n","  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.1.0/en_core_web_sm-3.1.0-py3-none-any.whl (13.6 MB)\n","     ---------------------------------------- 13.6/13.6 MB 4.5 MB/s eta 0:00:00\n","Requirement already satisfied: spacy<3.2.0,>=3.1.0 in c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages (from en-core-web-sm==3.1.0) (3.1.3)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.0.8)\n","Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.10.0.2)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.0.5)\n","Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.8.2)\n","Requirement already satisfied: jinja2 in c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.0.2)\n","Requirement already satisfied: thinc<8.1.0,>=8.0.9 in c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (8.0.10)\n","Requirement already satisfied: setuptools in c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (59.5.0)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.0.5)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.0.6)\n","Requirement already satisfied: numpy>=1.15.0 in c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.21.2)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.8.2)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.0.5)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.27.1)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (4.62.3)\n","Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.7.4)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.1 in c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.4.1)\n","Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.4.0)\n","Requirement already satisfied: pathy>=0.3.5 in c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.6.0)\n","Requirement already satisfied: packaging>=20.0 in c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (21.3)\n","Requirement already satisfied: zipp>=0.5 in c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.7.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages (from packaging>=20.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.0.4)\n","Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages (from pathy>=0.3.5->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (5.2.1)\n","Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.3)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.0.11)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.26.8)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2021.10.8)\n","Requirement already satisfied: colorama in c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.4.4)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (8.0.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages (from jinja2->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.0.1)\n","Requirement already satisfied: importlib-metadata in c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages (from click<9.0.0,>=7.1.1->typer<0.5.0,>=0.3.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (4.8.2)\n","[!] As of spaCy v3.0, shortcuts like 'en' are deprecated. Please use the full\n","pipeline package name 'en_core_web_sm' instead.\n","[+] Download and installation successful\n","You can now load the package via spacy.load('en_core_web_sm')\n"]},{"name":"stderr","output_type":"stream","text":["WARNING: Ignoring invalid distribution -orch (c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution - (c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -orch (c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution - (c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -orch (c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution - (c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -orch (c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution - (c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -orch (c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution - (c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -orch (c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution - (c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages)\n"]},{"name":"stdout","output_type":"stream","text":["Collecting de-core-news-sm==3.1.0\n","  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.1.0/de_core_news_sm-3.1.0-py3-none-any.whl (18.8 MB)\n","     --------------------------------------- 18.8/18.8 MB 10.6 MB/s eta 0:00:00\n","Requirement already satisfied: spacy<3.2.0,>=3.1.0 in c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages (from de-core-news-sm==3.1.0) (3.1.3)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (3.0.5)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (3.0.8)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.1 in c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (2.4.1)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (2.27.1)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (1.0.5)\n","Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (3.10.0.2)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (2.0.5)\n","Requirement already satisfied: setuptools in c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (59.5.0)\n","Requirement already satisfied: numpy>=1.15.0 in c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (1.21.2)\n","Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (0.8.2)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (2.0.6)\n","Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (0.7.4)\n","Requirement already satisfied: packaging>=20.0 in c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (21.3)\n","Requirement already satisfied: thinc<8.1.0,>=8.0.9 in c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (8.0.10)\n","Requirement already satisfied: pathy>=0.3.5 in c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (0.6.0)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (4.62.3)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (1.8.2)\n","Requirement already satisfied: jinja2 in c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (3.0.2)\n","Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (0.4.0)\n","Requirement already satisfied: zipp>=0.5 in c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (3.7.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages (from packaging>=20.0->spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (3.0.4)\n","Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages (from pathy>=0.3.5->spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (5.2.1)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (2021.10.8)\n","Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (3.3)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (1.26.8)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (2.0.11)\n","Requirement already satisfied: colorama in c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (0.4.4)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (8.0.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages (from jinja2->spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (2.0.1)\n","Requirement already satisfied: importlib-metadata in c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages (from click<9.0.0,>=7.1.1->typer<0.5.0,>=0.3.0->spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (4.8.2)\n","[!] As of spaCy v3.0, shortcuts like 'de' are deprecated. Please use the full\n","pipeline package name 'de_core_news_sm' instead.\n","[+] Download and installation successful\n","You can now load the package via spacy.load('de_core_news_sm')\n"]},{"name":"stderr","output_type":"stream","text":["WARNING: Ignoring invalid distribution -orch (c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution - (c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -orch (c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution - (c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -orch (c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution - (c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -orch (c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution - (c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -orch (c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution - (c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -orch (c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution - (c:\\users\\jiyoon\\anaconda3\\envs\\torchgpu\\lib\\site-packages)\n"]}],"source":["# !apt install python3.7\n","# !pip install -U torchtext==0.8.1\n","!python -m spacy download en\n","!python -m spacy download de"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jAM51Z7znq_V"},"outputs":[],"source":["# !git clone https://github.com/Jiyoon52/LG_time_series_day02_dataset.git # colab 사용시"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dYCNeMYEnq_Q"},"outputs":[],"source":["# Image('image/image_1.JPG') # 로컬 사용시\n","Image('/content/LG_time_series_day02_dataset/image/image_1.JPG') # colab 사용시"]},{"cell_type":"markdown","metadata":{"id":"9uXbP9sNnq_S"},"source":["# [Sequence to Sequence - many to many] "]},{"cell_type":"markdown","metadata":{"id":"QL7l9L4Jnq_T"},"source":["##### jupyter notebook 단축키\n","\n","- ctrl+enter: 셀 실행   \n","- shift+enter: 셀 실행 및 다음 셀 이동   \n","- alt+enter: 셀 실행, 다음 셀 이동, 새로운 셀 생성\n","- a: 상단에 새로운 셀 만들기\n","- b: 하단에 새로운 셀 만들기\n","- dd: 셀 삭제(x: 셀 삭제)"]},{"cell_type":"markdown","metadata":{"id":"Fr9IowEpnq_U"},"source":["### 1. 모듈 불러오기"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9ueLs11Jnq_W"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch import Tensor\n","\n","from torchtext.datasets import TranslationDataset, Multi30k\n","from torchtext.data import Field, BucketIterator\n","\n","import spacy\n","import numpy as np\n","\n","import random\n","import math\n","import time\n","\n","import torchtext\n","from torchtext.data.utils import get_tokenizer\n","from collections import Counter\n","from torchtext.vocab import Vocab\n","from torchtext.utils import download_from_url, extract_archive\n","from torch.nn.utils.rnn import pad_sequence\n","from torch.utils.data import DataLoader\n","import io\n","\n","import random\n","from typing import Tuple\n","\n","import warnings\n","warnings.filterwarnings(action='ignore') "]},{"cell_type":"markdown","metadata":{"id":"KL9O-z5Pnq_Y"},"source":["### 2. 데이터 불러오기"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vjnrikOSeZKU"},"outputs":[],"source":["'''\n","https://hoya012.github.io/blog/reproducible_pytorch/\n","'''\n","random_seed = 2022\n","torch.manual_seed(random_seed)\n","torch.cuda.manual_seed(random_seed)\n","torch.cuda.manual_seed_all(random_seed) # if use multi-GPU\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","np.random.seed(random_seed)\n","random.seed(random_seed)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y4t-KvVLnq_Z"},"outputs":[],"source":["url_base = 'https://raw.githubusercontent.com/multi30k/dataset/master/data/task1/raw/'\n","train_urls = ('train.de.gz', 'train.en.gz')\n","val_urls = ('val.de.gz', 'val.en.gz')\n","test_urls = ('test_2016_flickr.de.gz', 'test_2016_flickr.en.gz')\n","\n","train_filepaths = [extract_archive(download_from_url(url_base + url))[0] for url in train_urls]\n","val_filepaths = [extract_archive(download_from_url(url_base + url))[0] for url in val_urls]\n","test_filepaths = [extract_archive(download_from_url(url_base + url))[0] for url in test_urls]\n","\n","de_tokenizer = get_tokenizer('spacy', language='de_core_news_sm')\n","en_tokenizer = get_tokenizer('spacy', language='en_core_web_sm')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-mAj4KDieZKU"},"outputs":[],"source":["def build_vocab(filepath, tokenizer):\n","  counter = Counter()\n","  with io.open(filepath, encoding=\"utf8\") as f:\n","    for string_ in f:\n","      counter.update(tokenizer(string_))\n","  return Vocab(counter, specials=['<unk>', '<pad>', '<bos>', '<eos>'])\n","\n","de_vocab = build_vocab(train_filepaths[0], de_tokenizer)\n","en_vocab = build_vocab(train_filepaths[1], en_tokenizer)\n","\n","def data_process(filepaths):\n","  raw_de_iter = iter(io.open(filepaths[0], encoding=\"utf8\"))\n","  raw_en_iter = iter(io.open(filepaths[1], encoding=\"utf8\"))\n","  data = []\n","  for (raw_de, raw_en) in zip(raw_de_iter, raw_en_iter):\n","    de_tensor_ = torch.tensor([de_vocab[token] for token in de_tokenizer(raw_de)],\n","                            dtype=torch.long)\n","    en_tensor_ = torch.tensor([en_vocab[token] for token in en_tokenizer(raw_en)],\n","                            dtype=torch.long)\n","    data.append((de_tensor_, en_tensor_))\n","  return data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T06kbquBeZKV"},"outputs":[],"source":["train_data = data_process(train_filepaths)\n","val_data = data_process(val_filepaths)\n","test_data = data_process(test_filepaths)\n","\n","print(f'test_data length is {len(test_data)}')\n","print(f'val_data length is {len(val_data)}')\n","print(f'test_data length is {len(test_data)}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"otqg7TxbeZKV"},"outputs":[],"source":["train_data[0][0]\n","train_data[0][1]\n","\n","de_itos = de_vocab.itos\n","en_itos = en_vocab.itos\n","\n","exam_de = ([de_itos[i] for i in train_data[0][0]])\n","exam_en = ([en_itos[i] for i in train_data[0][1]])\n","\n","print('Germany sentence')\n","print(exam_de)\n","\n","print('English sentence')\n","print(exam_en)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a5UFu2oSeZKV"},"outputs":[],"source":["batch_size = 128\n","PAD_IDX = de_vocab['<pad>']\n","BOS_IDX = de_vocab['<bos>']\n","EOS_IDX = de_vocab['<eos>']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SZ9qFYpMeZKV"},"outputs":[],"source":["def generate_batch(data_batch):\n","  de_batch, en_batch = [], []\n","  for (de_item, en_item) in data_batch:\n","    de_batch.append(torch.cat([torch.tensor([BOS_IDX]), de_item, torch.tensor([EOS_IDX])], dim=0))\n","    en_batch.append(torch.cat([torch.tensor([BOS_IDX]), en_item, torch.tensor([EOS_IDX])], dim=0))\n","  de_batch = pad_sequence(de_batch, padding_value=PAD_IDX)\n","  en_batch = pad_sequence(en_batch, padding_value=PAD_IDX)\n","  return de_batch, en_batch"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U9W8oimleZKW"},"outputs":[],"source":["train_iter = DataLoader(train_data, batch_size,\n","                        shuffle=True, collate_fn=generate_batch)\n","valid_iter = DataLoader(val_data, batch_size,\n","                        shuffle=True, collate_fn=generate_batch)\n","test_iter = DataLoader(test_data, batch_size,\n","                       shuffle=True, collate_fn=generate_batch)"]},{"cell_type":"markdown","metadata":{"id":"zxG4ygKAnq_e"},"source":["### 3. Seq2Seq Modeling"]},{"cell_type":"markdown","metadata":{"id":"EvYMON05eZKW"},"source":["#### 3.1 Define the Model Structure"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jmJd0HwPnq_f"},"outputs":[],"source":["class Encoder(nn.Module):\n","    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout):\n","        super().__init__()\n","        \n","        self.hid_dim = hid_dim\n","        self.n_layers = n_layers\n","        \n","        self.embedding = nn.Embedding(input_dim, emb_dim)\n","        \n","        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)\n","        \n","        self.dropout = nn.Dropout(dropout)\n","        \n","    def forward(self, src):\n","        \n","        #src = [src len, batch size]\n","        \n","        embedded = self.dropout(self.embedding(src))\n","        \n","        #embedded = [src len, batch size, emb dim]\n","        \n","        outputs, (hidden, cell) = self.rnn(embedded)\n","        \n","        #outputs = [src len, batch size, hid dim * n directions]\n","        #hidden = [n layers * n directions, batch size, hid dim]\n","        #cell = [n layers * n directions, batch size, hid dim]\n","        \n","        #outputs are always from the top hidden layer\n","        \n","        return hidden, cell\n","\n","\n","class Decoder(nn.Module):\n","    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout):\n","        super().__init__()\n","        \n","        self.output_dim = output_dim\n","        self.hid_dim = hid_dim\n","        self.n_layers = n_layers\n","        \n","        self.embedding = nn.Embedding(output_dim, emb_dim)\n","        \n","        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)\n","        \n","        self.fc_out = nn.Linear(hid_dim, output_dim)\n","        \n","        self.dropout = nn.Dropout(dropout)\n","        \n","    def forward(self, input, hidden, cell):\n","        \n","        #input = [batch size]\n","        #hidden = [n layers * n directions, batch size, hid dim]\n","        #cell = [n layers * n directions, batch size, hid dim]\n","        \n","        #n directions in the decoder will both always be 1, therefore:\n","        #hidden = [n layers, batch size, hid dim]\n","        #context = [n layers, batch size, hid dim]\n","        \n","        input = input.unsqueeze(0)\n","        \n","        #input = [1, batch size]\n","        \n","        embedded = self.dropout(self.embedding(input))\n","        \n","        #embedded = [1, batch size, emb dim]\n","                \n","        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n","        \n","        #output = [seq len, batch size, hid dim * n directions]\n","        #hidden = [n layers * n directions, batch size, hid dim]\n","        #cell = [n layers * n directions, batch size, hid dim]\n","        \n","        #seq len and n directions will always be 1 in the decoder, therefore:\n","        #output = [1, batch size, hid dim]\n","        #hidden = [n layers, batch size, hid dim]\n","        #cell = [n layers, batch size, hid dim]\n","        \n","        prediction = self.fc_out(output.squeeze(0))\n","        \n","        #prediction = [batch size, output dim]\n","        \n","        return prediction, hidden, cell"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C3hUMUXyeZKW"},"outputs":[],"source":["class Seq2Seq(nn.Module):\n","    def __init__(self, encoder, decoder, device):\n","        super().__init__()\n","        \n","        self.encoder = encoder\n","        self.decoder = decoder\n","        self.device = device\n","        \n","        assert encoder.hid_dim == decoder.hid_dim, \\\n","            \"Hidden dimensions of encoder and decoder must be equal!\"\n","        assert encoder.n_layers == decoder.n_layers, \\\n","            \"Encoder and decoder must have equal number of layers!\"\n","        \n","    def forward(self, src, trg, teacher_forcing_ratio = 0.5):\n","        \n","        #src = [src len, batch size]\n","        #trg = [trg len, batch size]\n","        #teacher_forcing_ratio is probability to use teacher forcing\n","        #e.g. if teacher_forcing_ratio is 0.75 we use ground-truth inputs 75% of the time\n","        \n","        batch_size = trg.shape[1]\n","        trg_len = trg.shape[0]\n","        trg_vocab_size = self.decoder.output_dim\n","        \n","        #tensor to store decoder outputs\n","        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n","        \n","        #last hidden state of the encoder is used as the initial hidden state of the decoder\n","        hidden, cell = self.encoder(src)\n","        \n","        #first input to the decoder is the <sos> tokens\n","        input = trg[0,:]\n","        \n","        for t in range(1, trg_len):\n","            \n","            #insert input token embedding, previous hidden and previous cell states\n","            #receive output tensor (predictions) and new hidden and cell states\n","            output, hidden, cell = self.decoder(input, hidden, cell)\n","            \n","            #place predictions in a tensor holding predictions for each token\n","            outputs[t] = output\n","            \n","            #decide if we are going to use teacher forcing or not\n","            teacher_force = random.random() < teacher_forcing_ratio\n","            \n","            #get the highest predicted token from our predictions\n","            top1 = output.argmax(1) \n","            \n","            #if teacher forcing, use actual next token as next input\n","            #if not, use predicted token\n","            input = trg[t] if teacher_force else top1\n","        \n","        return outputs"]},{"cell_type":"markdown","metadata":{"id":"b5dlh2ojeZKX"},"source":["#### 3.2 Define The Training Testing Strategy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XMh3ENK1eZKX"},"outputs":[],"source":["def train(model: nn.Module,\n","          iterator: torch.utils.data.DataLoader,\n","          optimizer: optim.Optimizer,\n","          criterion: nn.Module,\n","          clip: float):\n","\n","    model.train()\n","\n","    epoch_loss = 0\n","\n","    for _, (src, trg) in enumerate(iterator):\n","        src, trg = src.to(device), trg.to(device)\n","\n","        optimizer.zero_grad()\n","\n","        output = model(src, trg)\n","\n","        output = output[1:].view(-1, output.shape[-1])\n","        trg = trg[1:].view(-1)\n","\n","        loss = criterion(output, trg)\n","\n","        loss.backward()\n","\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n","\n","        optimizer.step()\n","\n","        epoch_loss += loss.item()\n","\n","    return epoch_loss / len(iterator)\n","\n","\n","def evaluate(model: nn.Module,\n","             iterator: torch.utils.data.DataLoader,\n","             criterion: nn.Module):\n","\n","    model.eval()\n","\n","    epoch_loss = 0\n","\n","    with torch.no_grad():\n","\n","        for _, (src, trg) in enumerate(iterator):\n","            src, trg = src.to(device), trg.to(device)\n","\n","            output = model(src, trg, 0) #turn off teacher forcing\n","\n","            output = output[1:].view(-1, output.shape[-1])\n","            trg = trg[1:].view(-1)\n","\n","            loss = criterion(output, trg)\n","\n","            epoch_loss += loss.item()\n","\n","    return epoch_loss / len(iterator), output\n","  \n","def epoch_time(start_time: int,\n","               end_time: int):\n","    elapsed_time = end_time - start_time\n","    elapsed_mins = int(elapsed_time / 60)\n","    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n","    return elapsed_mins, elapsed_secs"]},{"cell_type":"markdown","metadata":{"id":"wM1f_xMdeZKY"},"source":["### 4. Model Training"]},{"cell_type":"markdown","metadata":{"id":"0a6w91s2eZKY"},"source":["#### 4.1 Hyperparameter Setting"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SckrBRcLeZKY"},"outputs":[],"source":["input_dim = len(de_vocab)\n","output_dim = len(en_vocab)\n","enc_emb_dim = 256\n","dec_emb_dim = 256\n","hid_dim = 512\n","n_layers = 2\n","enc_dropout = 0.5\n","dec_dropout = 0.5\n","num_epochs = 10\n","clip = 1\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else 'cpu') \n","best_model_path = f'./ckpt/seq2seq.pt'"]},{"cell_type":"markdown","metadata":{"id":"LKUkOsEeeZKZ"},"source":["#### 4.2 Construct Data Loaders and Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wFBRXRq-eZKZ"},"outputs":[],"source":["enc = Encoder(input_dim, enc_emb_dim, hid_dim, n_layers, enc_dropout)\n","dec = Decoder(output_dim, dec_emb_dim, hid_dim, n_layers, dec_dropout)\n","\n","model = Seq2Seq(enc, dec, device).to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rR4vPbh8eZKZ"},"outputs":[],"source":["def init_weights(m: nn.Module):\n","    for name, param in m.named_parameters():\n","        if 'weight' in name:\n","            nn.init.normal_(param.data, mean=0, std=0.01)\n","        else:\n","            nn.init.constant_(param.data, 0)\n","model.apply(init_weights)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DMCDrcNFeZKa"},"outputs":[],"source":["def count_parameters(model: nn.Module):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","print(f'The model has {count_parameters(model):,} trainable parameters')"]},{"cell_type":"markdown","metadata":{"id":"nRLTQOW7eZKa"},"source":["#### 4.3 Model Training and Save Weights(Parameters)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xVaxvSd3eZKa"},"outputs":[],"source":["optimizer = optim.Adam(model.parameters())\n","PAD_IDX = en_vocab.stoi['<pad>']\n","criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EyPYpMiteZKa","outputId":"e019dc45-4251-4244-fbfd-127beab405ee"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Epoch 1/200\n","train Loss: 1.6695 Acc: 0.3113\n","val Loss: 1.5663 Acc: 0.4220\n","\n","Epoch 10/200\n","train Loss: 0.7150 Acc: 0.9132\n","val Loss: 0.7994 Acc: 0.7672\n","\n","Epoch 20/200\n","train Loss: 0.2856 Acc: 0.9563\n","val Loss: 0.4950 Acc: 0.8337\n","\n","Epoch 30/200\n","train Loss: 0.1411 Acc: 0.9777\n","val Loss: 0.4882 Acc: 0.8108\n","\n","Epoch 40/200\n","train Loss: 0.0787 Acc: 0.9917\n","val Loss: 0.4549 Acc: 0.8212\n","\n","Epoch 50/200\n","train Loss: 0.0528 Acc: 0.9948\n","val Loss: 0.3743 Acc: 0.8482\n","\n","Epoch 60/200\n","train Loss: 0.0368 Acc: 0.9958\n","val Loss: 0.3734 Acc: 0.8545\n","\n","Epoch 70/200\n","train Loss: 0.0279 Acc: 0.9974\n","val Loss: 0.4751 Acc: 0.8337\n","\n","Epoch 80/200\n","train Loss: 0.0205 Acc: 0.9984\n","val Loss: 0.4611 Acc: 0.8503\n","\n","Epoch 90/200\n","train Loss: 0.0164 Acc: 0.9990\n","val Loss: 0.2133 Acc: 0.9106\n","\n","Epoch 100/200\n","train Loss: 0.0130 Acc: 0.9979\n","val Loss: 0.3155 Acc: 0.8690\n","\n","Epoch 110/200\n","train Loss: 0.0101 Acc: 0.9995\n","val Loss: 0.3882 Acc: 0.8607\n","\n","Epoch 120/200\n","train Loss: 0.0177 Acc: 0.9969\n","val Loss: 0.3560 Acc: 0.8524\n","\n","Epoch 130/200\n","train Loss: 0.0065 Acc: 1.0000\n","val Loss: 0.4877 Acc: 0.8586\n","\n","Epoch 140/200\n","train Loss: 0.0051 Acc: 1.0000\n","val Loss: 0.4037 Acc: 0.8690\n","\n","Epoch 150/200\n","train Loss: 0.0043 Acc: 1.0000\n","val Loss: 0.4161 Acc: 0.8690\n","\n","Epoch 160/200\n","train Loss: 0.0040 Acc: 1.0000\n","val Loss: 0.5355 Acc: 0.8607\n","\n","Epoch 170/200\n","train Loss: 0.0032 Acc: 1.0000\n","val Loss: 0.4463 Acc: 0.8628\n","\n","Epoch 180/200\n","train Loss: 0.0028 Acc: 1.0000\n","val Loss: 0.4591 Acc: 0.8711\n","\n","Epoch 190/200\n","train Loss: 0.0024 Acc: 1.0000\n","val Loss: 0.4081 Acc: 0.8836\n","\n","Epoch 200/200\n","train Loss: 0.0021 Acc: 1.0000\n","val Loss: 0.4118 Acc: 0.8753\n","\n","Training complete in 1m 12s\n","Best val Acc: 0.912682\n"]}],"source":["best_valid_loss = float('inf')\n","\n","for epoch in range(num_epochs):\n","\n","    start_time = time.time()\n","\n","    train_loss = train(model, train_iter, optimizer, criterion, clip)\n","    valid_loss, _ = evaluate(model, valid_iter, criterion)\n","\n","    end_time = time.time()\n","\n","    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n","\n","    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n","    print(f'\\tTrain Loss: {train_loss:.3f}')\n","    print(f'\\t Val. Loss: {valid_loss:.3f}')\n","\n","test_loss, pred = evaluate(model, test_iter, criterion)\n","torch.save(model.state_dict(), best_model_path)\n","print(f'| Test Loss: {test_loss:.3f}')"]},{"cell_type":"markdown","metadata":{"id":"hfvPo_VreZKa"},"source":["### 5. Model Validation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w_ZdPjMfeZKa"},"outputs":[],"source":["model.load_state_dict(torch.load(best_model_path))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fJMhU_MeeZKa","outputId":"da38f481-5924-4b9b-d93f-d71f12943bf0"},"outputs":[{"name":"stdout","output_type":"stream","text":["2\n","[1.6850166e-04 8.6520445e-03 9.9053156e-01 2.1985815e-04 4.7382757e-05\n"," 3.8065491e-04]\n"]}],"source":["test_loss, pred_output = evaluate(model, test_iterator, criterion)"]},{"cell_type":"markdown","metadata":{"id":"gqBHwh5-nq_q"},"source":["# EOD"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"5_Seq2Seq.ipynb","provenance":[{"file_id":"https://github.com/Jiyoon52/LG_ES_RNN/blob/main/5_Seq2Seq.ipynb","timestamp":1656959377536},{"file_id":"https://github.com/Jiyoon52/LG_time_series_day02_dataset/blob/main/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%EC%8B%9C%EA%B3%84%EC%97%B4%EB%B6%84%EC%84%9D%202%ED%9A%8C%EC%B0%A8%20-%201.ipynb","timestamp":1642046886935}]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.11"},"toc":{"base_numbering":"1","nav_menu":{},"number_sections":false,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{"height":"calc(100% - 180px)","left":"10px","top":"150px","width":"357.448px"},"toc_section_display":true,"toc_window_display":true}},"nbformat":4,"nbformat_minor":0}